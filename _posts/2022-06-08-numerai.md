---
layout: post
title: The Automation of the numer.ai competition through IBM Cloud
subtitle: An introduction to one of the world's hardest data science competitions (and one easy way to automate your participation in it)
gh-repo: DAVIDCRUZ0202/numerai_automation
gh-badge: [star, fork, follow]
---



![pic_of_numerai](https://github.com/DAVIDCRUZ0202/davidcruz0202.github.io/blob/master/assets/img/1.numerai.png?raw=true)
Whew, I haven't posted in a long time! I've been very busy with my full time role, but recently, I have been making time to further develop some of my side projects. I hope that this article serves newcomers to data science as well as advanced practitioners in one way or another. With this post, I'll aim to cover a number of different topic pertaining this interesting competition. I'll break down the numer.ai tournament in many different ways. I'll explain some of the challenges behind what makes it such a hard problem to do well with, and I'll walk through what I did as my methodology for the competition. I really hope that this helps some folks get started in data science and predictive modeling! My full github repository is available [here](https://github.com/DAVIDCRUZ0202/numerai_automation). Check it out for a really cool section on how to automate your workflow with IBM Cloud!

## Project Overview
[Numerai](numer.ai) is an ongoing weekly competition which is open to anyone who is willing to try it. Essentially, this tournament is designed to help in the management of a real-life hedge fund. The hedge fund behind numerai aims to be "The last hedge fund in the world", and it is aiming to achieve this by completely out-sourcing its quantitative analysis to a community of data science practitioners. In a traditional hedge fund, quantitative analysts use sensitive financial data to create signals and indicators for the movement of stock prices. It's reasonable to assume that this project can be held in comparison with other financialy analysis projects such as this [kaggle competitionIn](https://www.kaggle.com/competitions/ubiquant-market-prediction), but in reality, the actual participation of this project doesn't require much financial background at all! This is because, with numerai, we are tasked with the incredible task of achieving the same outcome as a financial analyst... with completely masked data.

## Problem Statement

Can you predict the performance of an anonymous stock ID, based on completely anonymized features?

![pic_of_data](https://github.com/DAVIDCRUZ0202/davidcruz0202.github.io/blob/master/assets/img/2.obfuscated_data.png?raw=true)

The data is completely obfuscated which means that we have no way of deciphering what the underlying asset is, nor what the features are truly representing. The competition is designed like this on purpose; because we are working to predict real values in the market, we need real data. The only way to get real financial data is through some expensive arrangements, but the founders have established a safe method for providing this same information without exposing sensitive information. So with masked data to work with, we are really reduced to machine learning and data science practices to help us not only create results, but improve upon them and refine them. I can't stress enough how awesome the numer.ai community is in helping each other learn and grow. As you get started with the competition, make sure you create an account and introduce yourself to the community of practitioners through their forum. 

![pic_of_forum](https://github.com/DAVIDCRUZ0202/davidcruz0202.github.io/blob/master/assets/img/3.numer.ai_forum.png?raw=true)

From the main page of [numer.ai](numer.ai) you can download an excellent starting folder which will provide you with all of the assets you will need to give a first pass. Follow the directions from their documentation and you will have a submission for the most recent week ready in no time! The process of creating predictions and submitting them to numerai can be a cumbersome process to manually do on a weekly basis, so luckily, numer.ai has provided a walkthrough as to how to automate this process with AWS and CLI tools. Now, this is a great solution for automation and I want to really thank the community for providing this guidance. On my end, I wanted to achieve this same automation, but being that I'm well versed in the world of IBM software and technology, I had to take a step back and see what I could do to achieve this same level of automation with a different software platform. I've succeeded in just that; [the numer.ai competition is now fully automated through IBM Cloud!](https://github.com/DAVIDCRUZ0202/numerai_automation)

### Evaluation Metrics
This competition is scored based on a variety of evaluation metrics which are explained in detail [here](https://docs.numer.ai/tournament/true-contribution-tc) [here](https://docs.numer.ai/tournament/metamodel-contribution) and [here](https://docs.numer.ai/tournament/feature-neutral-correlation). All of these methods have unique qualities to them, but a universally agreed upon method for gauging model performance is the [spearman's correlation](https://forum.numer.ai/t/pearson-vs-spearman-scoring-confusion/2559/2) coefficient and regular coefficient of correlation. I score my models with these metrics as well as including the r2 score which serves to show which models are working to predict actual values rather than just random information.

![summary_stats](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/Model_Building/assets/2.evaluation_metrics.png?raw=true)

## Analysis

### EDA and Visualizations
Here's the quick and fast: The data is obfuscated(masked), and also fully cleaned, normalized, centered. This means that the data is ready to be worked on with machine learning models right away. For due diligence and proof of this, I'll share some visuals and outcomes of some of my analysis. As always, you can read through the notebook to see more details.

* The data has a uniform distribution of values for features, and a normal distribution of values for the target. There are no null values.

![summary_stats](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/1.summary_stats.png?raw=true)

* The `era` feature gives us a temporal quality to monitor, but it's still a highly complicated concept to further engineer in new and helpful ways. Here is a chart which shows the varying size of eras

![eras](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/2.era_sizes.png?raw=true)

* Our `target` feature is normally distributed

![target_dist](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/3.target_dist.png?raw=true)

* also, the `target` is centered around it's mean (notice the range of values on the y-axis)

![target_cent](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/4.target_centered.png?raw=true)

* intra-feature correlations show us that features with similar prefixes have varying levels of correlation

![feature_corrs](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/5.feature_corrs.png?raw=true)

* A high level heatmap shows us that the data set is overall not correlated in any specific direction.

![heatmap](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/EDA/assets/6.heatmap.png?raw=true)

## Methodology


### Data Preprocessing
Since this data has already been cleaned, we don't have to any vital data pre-processing. The process of cleaning and obfuscating the data is covered in detail [here](https://docs.numer.ai/community-content/understanding-numerai/numerai-structure#user-models). For the sake of our competition submissions, I created a small data cleaning function which takes in the training data and returns a train / test split which is ready for training and testing with models.

![clean_data](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/Model_Building/assets/1.clean_data.png?raw=true)

### Model Building and Implementation

For model development, we cover the entire process from pre-processing, to model implementation, metrics, and refinement. I recommend reading through the actual notebook where I write about the technical results of each process. It holds many more insights which I do not share in this blog post. If you're on a time crunch then just read through this readme and you should still get the summary of the work that has been done ðŸ˜„

### Model Implementation

To prove the concept of automation with ibm cloud, I initially fitted and predicted with a simple linear regression model. I follow this by creating a function which tests a larger number of pre-built algorithms to observe the general performance of all of these different models. By observing the performance of these models, I can make more specific choices as to what I want to incorporate and what I can exclude from my research.

![model_choice](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/Model_Building/assets/3.func_1.png?raw=true)

## Refinement
After observing initial results, I used a similar function to examing some more results from some more advanced algorithms. This process produced some of the best model choices available to me, and I was able to take some more precise decisions in what my final model would look like.

![model_choice_2](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/Model_Building/assets/4.func_2.png?raw=true)


## Model Evaluation and Validation

So with the final choices in hand, for a final pass at model choice, I created a cross validation pipeline to choose the best hyperparameters for my model. This ensured that without any additional feature engineering, I am using a model which is dependable in it's ability to make predictions. This final model from the cross validation process is the model that will stay with my project for a long time.

![cv](https://github.com/DAVIDCRUZ0202/numerai_automation/blob/main/notebooks/Model_Building/assets/5.cross_val.png?raw=true)

## Results

### Justification
After testing the final model, we find that we almost double our correlation metric from our original OLS regression model. We ended up with a gradient boosting regressor, and so we can see the improvements in our product as a result of using a model which accelerates learning on gradients which show steeper curves and also the fact that we are using decision trees which provide predictions of values instead of a single regression line, as is found in regression.


## Conclusion

### Reflection
Upon completing this workflow , I see a lot of potential for improvement. I am overall very happy that I am able to contribute the novel workflow of automating this process with IBM Cloud at no cost to users. I believe that my solution to  automation is actually a more streamlined process of what is available with AWS and the CLI, thanks to the power of notebook jobs from IBM's CP4D platform. Hopefully this workflow inspires more practitioners to deploy their own solutions and to continue to build upon the results of those deployments.

### Improvement
Besides defining my evaluation metrics, I have really not spent much time researching the available knowledge from numerai's community. Some next steps include spending more time with the numer.ai community to share insights as well as to learn a lot more from what they have to offer. There has been a plethora of material and ideation taking place within their forums and I highly recommend anyone interested to explore their archives. For immediate next steps for my project, improvement is definitely possible with some advanced feature engineering. Engineering features to consider some features more heavily than others, or considering some eras more heavily than others will surely prove to show some different outcomes. Thankfully this competition provides me with the perfect place to practice and enhance my skills.


This blog post barely scratches the surface for everything that has to do with the numer.ai competition. As far as the data goes, we can go into deep-dive discussions about the structure of the data, the relationships that we can uncover, and how we can get into some more advanced feature engineering with what we have to work with. With modeling, we could explore a wide variety of machine learning models that can be fit to predict this data, and why some models are better than others. I strongly recommend reading through the readme's and notebooks I've provided in my [github repo](https://github.com/DAVIDCRUZ0202/numerai_automation) and also, I highly recommend researching through the forums of numer.ai to learn and contribute your ideas. As far as automation goes, click on the link to my github repository above and read the readme for directions on how to achieve hands-off participation via IBM Cloud. 
